////
This guide is maintained in the main Quarkus repository
and pull requests should be submitted there:
https://github.com/quarkusio/quarkus/tree/main/docs/src/main/asciidoc
////
= Braineous Documentation version (1.0-CR2) Candidate Release 2
include::_attributes.adoc[]
:categories: official-documentation
:summary: Official Developer Documentation.
:numbered:
:sectnums:
:sectnumlevels: 4
:topics: official-documentation

:url: https://github.com/bugsbunnyshah/braineous_dataplatform/releases/download/braineous-1.0.0-CR1/create-connector.zip
:imagesdir: ../assets

== Core Concepts

=== Pipeline

==== What is a Pipeline?

A data pipeline connects the data source to a target store/system. The data source generates the data and posts it to the Braineous ingestion system via the Braineous Data Ingestion Java SDK. Braineous
data pipeline engine supports multiple data sources and multiple
target systems that can be associated with a single pipe.
In turn it supports as many pipes that maybe necessary for
the applications in question at scale.

==== Building Blocks

* *PipeId* : The *'pipeId'* uniquely identifies a pipeline to be managed by Braineous.
The Braineous ingestion engine can manage and monitor thousands of pipelines on
a single of instance of the Braineous server.

* *Entity* : The *'entity'* indicates the type of dataset that would be processed by
a Braineous pipeline. Multiple entities can be processed by a single pipeline as
the datasets are partitioned by 'staging stores' and the 'datalake store' associated with
a pipeline.

* *Staging Store* : A *'staging store'* is the final destination of delivery for a pipeline.
A pipeline can deliver to multiple stores in real time with network latency the only
environmental factor.

* *DataLake Store* : A *'datalake store'* is the internal store the pipeline delivers the
data for applications that have usecases related to analytics and machine learning. Braineous
is built on Apache Flink as its data processing engine and supports Apache Hive as its core
data lake. Future releases of Braineous will include a Data Lake Connector framework that
can support third-party data lakes like Apache Iceberg, Snowflake or a custom data lake
developed by the customer.

== Develop a Pipeline

link:/braineous/get-started[Get Started]

== Staging Store

==== What is a Staging Store?

A *'staging store'* is the final destination of delivery for a pipeline.
A pipeline can deliver to multiple stores in real time with network latency the only
environmental factor.


Logically, a staging store is identified by its *pipeId* and *entity*

===== Pipe Configuration

A sample Braineous pipe configuration

[source,bash,subs=attributes+]
----
{
  "pipeId": "multiplestores",
  "entity": "books",
  "configuration": [
    {
      "stagingStore" : "com.appgallabs.dataplatform.targetSystem.core.driver.MongoDBStagingStore",
      "name": "multiplestores0",
      "config": {
        "connectionString": "mongodb://localhost:27017",
        "database": "multi0",
        "collection": "data",
        "jsonpathExpressions": []
      }
    },
    {
      "stagingStore" : "com.appgallabs.dataplatform.targetSystem.core.driver.MongoDBStagingStore",
      "name": "multiplestores1",
      "config": {
        "connectionString": "mongodb://localhost:27017",
        "database": "multi1",
        "collection": "data",
        "jsonpathExpressions": []
      }
    }
  ]
}
----

* *pipeId* : As a data source provider, this is id identifies
this data pipe uniquely with the Braineous Data Pipline Engine.
* *configuration.storeDriver* : MongoDB target store driver
* *name* : a user-friendly way to indentify the target store
* *config.connectionString* : MySql database connection string
* *config.username* : Database User
* *config.password* : Database Password

A data pipe can be configured with multiple target stores/systems associated with the same data pipe
for data delivery.

The current Release, supports the following target stores

* MongoDB
* MySql

In the future releases, Braineous team will add support for more target stores and systems such as :

* Postgresql
* Oracle
* Snowflake
* Airbyte Catalog

Braineous also provides a *Staging Store Framework* for developers to develop custom connectors.

== DataLake Store

==== What is a Data Lake Store?

A *'datalake store'* is the internal store the pipeline delivers the
data for applications that have usecases related to analytics and machine learning. Braineous
is built on Apache Flink as its data processing engine and supports Apache Hive as its core
data lake. Future releases of Braineous will include a Data Lake Connector framework that
can support third-party data lakes like Apache Iceberg, Snowflake or a custom data lake
developed by the customer.

== Data Transformation

==== What is Data Transformation?

== Pipeline Monitoring

== Usecases

==== Extract/Transform/Load (ETL)

==== Extract/Load/Transform (ELT)

==== Analytics

==== Machine Learning



