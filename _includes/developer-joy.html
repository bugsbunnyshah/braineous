<div class="full-width-bg component">
  <div class="grid-wrapper">
    <div class="width-9-12 width-12-12-m">
      <p class="intropara">
        Braineous transforms any data-format, XML, CSV, into JSON for its processor.
        Once JSON a simple Object Graph and uses configured JSONPATH-expressions
        to produce data for the target system and delivers it to desired data-format.

        Completely dynamic. Just change the pipe configuration and roll.
      </p>
      <p class="intropara">
        A data pipeline connects the data source to a target store/system. The data
        source generates the data and posts it to the Braineous ingestion system
        via the Braineous Data Ingestion Java SDK.

        Braineous data pipeline engine supports multiple data sources and multiple
        target systems that can be associated with a single pipe.

        In turn it supports as many pipes that maybe necessary for the applications in
        question at scale.
      </p>
      <img src="../guides/images/build-time-principle.png" alt="Quarkus Build Time Principle" width="90%">
    </div>

    <div class="width-12-12 width-12-12-m">
      <h2>Pipe Registration</h2>
      <p>
      <p>
      <pre class="highlightjs highlight">
          <code class="language-java hljs" data-lang="java">
          <span class="hljs-meta">
          {
              "pipeId": "123",
              "configuration": [
                {
                  "storeDriver" : "com.appgallabs.dataplatform.receiver.core.driver.MongoDBStoreDriver",
                  "name": "scenario2_store0",
                  "config": {
                    "connectionString": "mongodb://localhost:27017",
                    "database": "scenario2_store0",
                    "collection": "data"
                  },
                  "jsonpathExpression": "jsonpath:1"
                },
                {
                  "storeDriver" : "com.appgallabs.dataplatform.receiver.core.driver.MongoDBStoreDriver",
                  "name": "scenario2_store1",
                  "config": {
                    "connectionString": "mongodb://localhost:27017",
                    "database": "scenario2_store1",
                    "collection": "data"
                  },
                  "jsonpathExpression": "jsonpath:1"
                }
              ]
          }
          </span></code>
      </pre>
      </p>

      <h2>Data Ingestion</h2>
      <p>
        The Data Ingestion process starts by sending data to the BRAINEOUS Data Ingestion endpoint. It is processed
        asynchronously as the data moves through its pipe through an Apache Kafka Topic and an Apache Flink
        Stream Processor
      </p>
      <p>
        Each ingestion goes through an ordered process of phases which are
        <u>
          <li>Validation</li>
          <li>Transformation</li>
          <li>Cleansing especially for Machine Learning applications</li>
          <li>Delivery to the Target system</li>
        </u>
      </p>

      <h2>Pipeline Registration Update</h2>
      <p>
        BRAINEOUS' Pipeline Engine is completely dynamic.
        You can add or remove Target Stores/Systems by updating
        the Registration via the BRAINEOUS Pipeline Management
        Endpoint.
      </p>

      <h2>Data Ingestion Java SDK</h2>
      <p>
        You can send data to the BRAINEOUS Data Ingestion engine using the
        included Java Data Ingestion SDK or directly via the REST API.

        The advantage of using the SDK has benefits of pre-processing
        optimizations such as:

        <u>
          <li>Tenant Authentication</li>
          <li>Data Throttling</li>
          <li>GraphQL endpoint to query the ingested data (planned for CR2 release)</li>
        </u>
      </p>

      <h2>Data Ingestion REST API</h2>
      <p>
      </p>
    </div>
  </div>
</div>
